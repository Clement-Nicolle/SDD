{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cdmxavJ-NnNJ"
   },
   "source": [
    "# Subject 67 - Invariant Risk Minimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "qCqu0PLrJdwu"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wGcd3EHYomBj"
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook presents essential results studied in the article **Invariant Risk Minimization** that can be found at https://arxiv.org/pdf/1907.02893.pdf.\n",
    "Because most machine learning algorithms depend on the assumption that training and testing data are sampled independently from the same distribution, it is common practice to shuffle at random the training and testing sets. Nevertheless, this article suggests this is not always the best solution, in fact the origin of your data can contain some useful details and shuffling between all of them can discard some information. To adress this issue, the authors purpose another way of training model.\n",
    "\n",
    "Before introucing this new idea, let's see first what can go wrong with traditional machine learning model through 2 examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9izaI_9HpamG",
    "tags": []
   },
   "source": [
    "### First one : an abstract one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WE0Lbu3u8GSv"
   },
   "source": [
    "Suppose you are working on an image classification task and you want to determine for each images whether it is a cow image or a camel one. Owing a set of images like the ones below you will surely train a CNN to deal with this task.\n",
    "<table><tr>\n",
    "<td> <img src=\"images/vache1.jpg\" alt=\"Drawing\" style=\"width: 300px;\"/> </td>\n",
    "<td> <img src=\"images/chameau1.jpg\" alt=\"Drawing\" style=\"width: 300px;\"/> </td>\n",
    "</tr></table>\n",
    "<table><tr>\n",
    "<td> <img src=\"images/vache2.jpg\" alt=\"Drawing\" style=\"width: 300px;\"/> </td>\n",
    "<td> <img src=\"images/chameau2.jpg\" alt=\"Drawing\" style=\"width: 300px;\"/> </td>\n",
    "</tr></table>\n",
    "\n",
    "Unfortunately it is much probable that your neural network fails to classify such image :\n",
    "<table><tr>\n",
    "<td> <img src=\"images/vache_desert.jpeg\" alt=\"Drawing\" style=\"width: 300px;\"/> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-Ht026RpjEf"
   },
   "source": [
    "### Second one : a more concrete example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJFGQs_jpqlF"
   },
   "source": [
    "We consider here the three following random variables defined on a set of some environnement $e\\in\\xi_{all} $ as :\n",
    "$$$$\n",
    "$$X_1^e \\sim \\mathcal{N}(0,\\,\\sigma^{2}_e)$$\n",
    "$$Y^e \\sim X_1^e + \\mathcal{N}(0,\\,\\sigma^{2}_e)$$\n",
    "$$X_2^e \\sim Y^e + \\mathcal{N}(0,\\,1)$$\n",
    "$$$$\n",
    "where $\\xi_{all} $ denotes the set of all possible/existing envoironnement.\n",
    "$$$$\n",
    "\n",
    "According to you, what will happen if we decide to predict $Y$, knowing $X_1$ and $X_2$ ?\n",
    "\n",
    "$$$$\n",
    "Just before pursuing this case, let's compute now some statistics about these random variables which will be useful later :\n",
    "\n",
    "$\\sigma^2(X_1^e)=\\sigma^{2}_e$,\n",
    "\n",
    "$\\sigma^2(Y^e)=2\\sigma^{2}_e$,\n",
    "\n",
    "$\\sigma^2(X_2^e)=2\\sigma^{2}_e+1$,\n",
    "\n",
    "$\\sigma(X_1^e,Y^e)=\\sigma^{2}_e$,\n",
    "\n",
    "$\\sigma(X_2^e,Y^e)=2\\sigma^{2}_e$,\n",
    "\n",
    "$\\sigma^2(X_1^e,X_2^e)=\\sigma^{2}_e$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KhhhPF7PxwVX"
   },
   "source": [
    "In order to predict $Y$, we will consider the three different linear regressions : $Y^e=aX_1^e+c$, $Y^e=bX_2^e+c$ and $Y^e=aX_1^e+bX_2^e+c$ and realize each regression on two distinct environnements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_EYv0a2OpiVx"
   },
   "outputs": [],
   "source": [
    "#Define our random variables on two different environnements\n",
    "\n",
    "n = 10000 # number of samples for each environnement \n",
    "\n",
    "sigma1 = 10 # variance for the environnement 1 noise \n",
    "X1e1 = np.random.normal(0,sigma1,n).reshape(-1,1)\n",
    "Ye1 = X1e1 + np.random.normal(0,sigma1,n).reshape(-1,1)\n",
    "X2e1 = Ye1 + np.random.normal(0,1,n).reshape(-1,1)\n",
    "\n",
    "sigma2 = 0.1 # variance for the environnement 2 noise \n",
    "X1e2 = np.random.normal(0,sigma2,n).reshape(-1,1)\n",
    "Ye2 = X1e2 + np.random.normal(0,sigma2,n).reshape(-1,1)\n",
    "X2e2 = Ye2 + np.random.normal(0,1,n).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "FRk7D2tf1akC"
   },
   "outputs": [],
   "source": [
    "def regressor(Y, Xs):\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(np.concatenate(Xs, axis=1),Y)\n",
    "    return lr.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "k3O3l37J1OHn"
   },
   "outputs": [],
   "source": [
    "reg1_env1 = regressor(Ye1,[X1e1])\n",
    "reg2_env1 = regressor(Ye1,[X2e1])\n",
    "reg3_env1 = regressor(Ye1,[X1e1,X2e1])\n",
    "\n",
    "reg1_env2 = regressor(Ye2,[X1e2])\n",
    "reg2_env2 = regressor(Ye2,[X2e2])\n",
    "reg3_env2 = regressor(Ye2,[X1e2,X2e2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7VwuJcaV1GRI",
    "outputId": "2e98992e-1b36-47ab-8b8f-13cd33c79dc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By running such regressions (despite different environnements), one might naively expect to \n",
      "have quite the same results for each pair of regressions on both environnement but this is not \n",
      "the case. \n",
      "For the first regression we obtain 0.996474 as coefficient on environnement 1 and 1.004092 \n",
      "on environnement 2.\n",
      "For the second regression we obtain 0.995075 as coefficient on environnement 1 and 0.018855 \n",
      "on environnement 2.\n",
      "For the third regression we obtain the couple (0.009765, 0.990180) as coefficients on \n",
      "environnement 1 and (0.994990, 0.009961) on environnement 2.\n"
     ]
    }
   ],
   "source": [
    "print(\"By running such regressions (despite different environnements), one might naively expect to \\nhave quite the same results for each pair of regressions on both environnement but this is not \\nthe case. \\nFor the first regression we obtain %f as coefficient on environnement 1 and %f \\non environnement 2.\\nFor the second regression we obtain %f as coefficient on environnement 1 and %f \\non environnement 2.\\nFor the third regression we obtain the couple (%f, %f) as coefficients on \\nenvironnement 1 and (%f, %f) on environnement 2.\" % (reg1_env1, reg1_env2, reg2_env1, reg2_env2, reg3_env1[0], reg3_env1[1], reg3_env2[0], reg3_env2[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zx-Z7G5T7dP3"
   },
   "source": [
    "In our study case, only the regression $Y^e=aX_1^e+c$ has given the same result on both environnement, let's see more in detail why we obtained these result.\n",
    "\n",
    "Our linear regressor as it is defined solve the Least Square Criterion $$min \\frac1n\\sum\\limits_{k=1}^n(y_k-a_1X_1-...-a_mX_m+b)^2$$\n",
    "$$$$\n",
    "The calculation of the annulation point of the gradient (with respect to $(a_i)_i,b$) gives :\n",
    "$$$$\n",
    "$$\\begin{cases}\n",
    "a_1\\sigma^2(x_1)  &=\\sigma(x_1,y) \\\\\n",
    "b &=\\bar{y}-a_1\\bar{x_1}\n",
    "\\end{cases}\\leftrightarrow\\begin{cases}\n",
    "a_1  &=\\frac{\\sigma(x_1,y)}{\\sigma^2(x_1)} \\\\\n",
    "b &=\\bar{y}-a_1\\bar{x_1} \\\\\n",
    "\\end{cases}$$ for the 1D case \n",
    "and : \n",
    "$$$$\n",
    "$$\\begin{cases}\n",
    "a_1\\sigma^2(x_1) + a_2\\sigma(x_1,x_2)  &=\\sigma(x_1,y) \\\\\n",
    "a_1\\sigma(x_1,x_2) + a_2\\sigma^2(x_2)  &=\\sigma(x_2,y) \\\\\n",
    "b &=\\bar{y}-a_1\\bar{x_1}-a_2\\bar{x_2} \\\\\n",
    "\\end{cases}\\leftrightarrow\\begin{cases}\n",
    "a_1  &=\\frac{\\sigma^2(x_2)\\sigma(x_1,y)-\\sigma(x_1,x_2)\\sigma(x_2,y)}{\\sigma^2(x_1)\\sigma^2(x_2)-\\sigma(x_1,x_2)^2} \\\\\n",
    "a_2  &=\\frac{\\sigma^2(x_1)\\sigma(x_2,y)-\\sigma(x_1,x_2)\\sigma(x_1,y)}{\\sigma^2(x_1)\\sigma^2(x_2)-\\sigma(x_1,x_2)^2} \\\\\n",
    "b &=\\bar{y}-a_1\\bar{x_1}-a_2\\bar{x_2} \\\\\n",
    "\\end{cases}$$ for the 2D case \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w11TaVcYGBYp"
   },
   "source": [
    "Using these results on our original regressions gives the following analytical solutions :\n",
    "\n",
    "Coefficients for the three regressions are respectively $1, \\frac{\\sigma^2_e}{\\sigma^2_e+0.5}$ and $(\\frac{1}{\\sigma^2_e+1},\\frac{\\sigma^2_e}{\\sigma^2_e+1})$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JMtNe_Bw4Ga7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
